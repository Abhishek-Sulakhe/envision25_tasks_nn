{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fv7rHhz7hmW8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Le0gvAlq0h-Y"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(preds, labels):\n",
        "    \"\"\"\n",
        "    Computes the accuracy between predictions and true labels.\n",
        "\n",
        "    Args:\n",
        "        preds (torch.Tensor): Model outputs (logits or probabilities).\n",
        "        labels (torch.Tensor): True class labels.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy as a percentage.\n",
        "    \"\"\"\n",
        "    # If preds are raw scores (logits), get predicted class by taking argmax\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "\n",
        "    correct = (preds == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7twuDLGg5YDJ"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Pqqpsch8dX",
        "outputId": "c253f875-5155-4c2f-f8d3-483cacec99f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.06MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 159kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.45MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.24MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Train data\n",
        "training_data = datasets.MNIST(\n",
        "    root = \"/content\" ,\n",
        "    train=True ,\n",
        "    download=True ,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "#Test Data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"/content\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "i-ZEOnGMmmlZ",
        "outputId": "a320f349-3ab4-48f9-9e13-e63bf37fa3f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.MNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py</a>`MNIST &lt;http://yann.lecun.com/exdb/mnist/&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``MNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``MNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 20);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "torchvision.datasets.mnist.MNIST"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sDCjIegmnbh",
        "outputId": "f35f0329-dfb9-488b-9d5c-2c0789bebb17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /content\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJs1HmRZOni5",
        "outputId": "378b0d72-28fc-40d0-bd83-f13dec2756ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dOgx6NjGmpjs"
      },
      "outputs": [],
      "source": [
        "image , label = training_data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ubPDTeY1YD",
        "outputId": "570b1fa0-0247-4eac-9db2-4e929eddb947"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image.shape , label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "xNPdLk5qVbTh",
        "outputId": "5452e016-fa06-4629-f3aa-95a234759200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b69770e1050>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(image.squeeze() , cmap= \"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PbCveOHMY2vu"
      },
      "outputs": [],
      "source": [
        "train_data_loader=DataLoader(dataset=training_data,\n",
        "                            batch_size=64,\n",
        "                             shuffle=True\n",
        "                             )\n",
        "\n",
        "test_data_loader=DataLoader(dataset=test_data,\n",
        "                            batch_size=64,\n",
        "                            shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "5wmIGzIg-uQC",
        "outputId": "6ef22545-8bf7-42ae-f3ef-87b10037114d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[_T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;, in_order: bool=True)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py</a>Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
              "\n",
              "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
              "iterable-style datasets with single- or multi-process loading, customizing\n",
              "loading order and optional automatic batching (collation) and memory pinning.\n",
              "\n",
              "See :py:mod:`torch.utils.data` documentation page for more details.\n",
              "\n",
              "Args:\n",
              "    dataset (Dataset): dataset from which to load the data.\n",
              "    batch_size (int, optional): how many samples per batch to load\n",
              "        (default: ``1``).\n",
              "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
              "        at every epoch (default: ``False``).\n",
              "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
              "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
              "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
              "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
              "        returns a batch of indices at a time. Mutually exclusive with\n",
              "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
              "        and :attr:`drop_last`.\n",
              "    num_workers (int, optional): how many subprocesses to use for data\n",
              "        loading. ``0`` means that the data will be loaded in the main process.\n",
              "        (default: ``0``)\n",
              "    collate_fn (Callable, optional): merges a list of samples to form a\n",
              "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
              "        map-style dataset.\n",
              "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
              "        into device/CUDA pinned memory before returning them.  If your data elements\n",
              "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
              "        see the example below.\n",
              "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
              "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
              "        the size of dataset is not divisible by the batch size, then the last batch\n",
              "        will be smaller. (default: ``False``)\n",
              "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
              "        from workers. Should always be non-negative. (default: ``0``)\n",
              "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
              "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
              "        input, after seeding and before data loading. (default: ``None``)\n",
              "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
              "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
              "        be used. (default: ``None``)\n",
              "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
              "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
              "        ``base_seed`` for workers. (default: ``None``)\n",
              "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
              "        in advance by each worker. ``2`` means there will be a total of\n",
              "        2 * num_workers batches prefetched across all workers. (default value depends\n",
              "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
              "        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n",
              "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
              "        the worker processes after a dataset has been consumed once. This allows to\n",
              "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
              "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
              "        ``True``.\n",
              "    in_order (bool, optional): If ``False``, the data loader will not enforce that batches\n",
              "        are returned in a first-in, first-out order. Only applies when ``num_workers &gt; 0``. (default: ``True``)\n",
              "\n",
              "\n",
              ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
              "             cannot be an unpicklable object, e.g., a lambda function. See\n",
              "             :ref:`multiprocessing-best-practices` on more details related\n",
              "             to multiprocessing in PyTorch.\n",
              "\n",
              ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
              "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
              "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
              "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
              "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
              "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
              "             loading to avoid duplicate data.\n",
              "\n",
              "             However, if sharding results in multiple workers having incomplete last batches,\n",
              "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
              "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
              "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
              "             cases in general.\n",
              "\n",
              "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
              "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
              "             `Multi-process data loading`_.\n",
              "\n",
              ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
              "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
              "\n",
              ".. warning:: Setting `in_order` to `False` can harm reproducibility and may lead to a skewed data\n",
              "             distribution being fed to the trainer in cases with imbalanced data.\n",
              "\n",
              ".. _multiprocessing context:\n",
              "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 130);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LspKIBiLD6iL",
        "outputId": "a31ed524-94a1-4634-afe2-70876dd795b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 938)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_loader.batch_size , len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqCC254sqBv8",
        "outputId": "51acb054-6c96-4908-f722-fbf49318987a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 157)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data_loader.batch_size , len(test_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "lMN74lqMuE8P"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,input_size,hidden_units,output_size):\n",
        "    super().__init__()\n",
        "    self.cnn_block1= nn.Sequential(\n",
        "        nn.Conv2d( in_channels=1 ,\n",
        "                  out_channels=10,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1\n",
        "                  ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(\n",
        "            in_channels=10,\n",
        "            out_channels=10,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.cnn_block2= nn.Sequential(\n",
        "      nn.Conv2d( in_channels=10,\n",
        "                out_channels=10,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1\n",
        "                ),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(\n",
        "          in_channels=10,\n",
        "          out_channels=10,\n",
        "          kernel_size=3,\n",
        "          stride=1,\n",
        "          padding=1,\n",
        "      ),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.layers=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_size,hidden_units),\n",
        "        # nn.ReLU(),\n",
        "        nn.Linear(hidden_units,output_size),\n",
        "        # nn.ReLU(),\n",
        "    )\n",
        "  def forward(self,X):\n",
        "    y= self.cnn_block1(X)\n",
        "    y=self.cnn_block2(y)\n",
        "    # y=self.cnn_block2(y)\n",
        "    # print(y.shape)\n",
        "    y=self.layers(y)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVruNdml_Vhn",
        "outputId": "642a576a-42f3-4157-e91a-d54bb6a7ecb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(\n",
              "  (cnn_block1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (cnn_block2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layers): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=30, bias=True)\n",
              "    (2): Linear(in_features=30, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Model(490,30,len(training_data.classes))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "C6K97z-rGAqA"
      },
      "outputs": [],
      "source": [
        "lossfn=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.01,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79mHCCbX-9_7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "35de48b0693b44f8a541c7c8366afc9c",
            "582befcd59dc49da9bcece5427f47605",
            "9255ecee9278468fbe87f6f8a581f80e",
            "35bd6c809776438687d697c8f73cd81d",
            "42197ff786a845da89f919e85ae7f561",
            "d305df4014fb46f5ac1c1e3ccf9f812e",
            "be096a56515445078b7ba6abbf8d50f6",
            "8528dd5decd84f3c823190ecb779ab44",
            "93940c52e845421995aa8363ec6a2e98",
            "92def21ee7fb44a89e4b72ac1a546935",
            "298d06ac9e3b476db48667bbcd74d2f6"
          ]
        },
        "id": "YOB23uDlix8H",
        "outputId": "aafbcc92-f0e9-48b8-fd9d-d36997ef4a27"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35de48b0693b44f8a541c7c8366afc9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test loss for each epoch = [tensor(0.0937, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0590, device='cuda:0'), tensor(0.0654, device='cuda:0'), tensor(0.0788, device='cuda:0'), tensor(0.0576, device='cuda:0'), tensor(0.0589, device='cuda:0'), tensor(0.0953, device='cuda:0'), tensor(0.0667, device='cuda:0'), tensor(0.0508, device='cuda:0')]\n",
            "test Accuracy=98.48726114649682\n",
            "[tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0749, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0723, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0696, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>), tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)]\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "EPOCH=10\n",
        "train_loss_values=[]\n",
        "test_loss_values=[]\n",
        "for epoch in tqdm(range(EPOCH)):\n",
        "\n",
        "  train_loss=0\n",
        "  for batch , (X,y) in enumerate(train_data_loader):\n",
        "    X=X.to(device)\n",
        "    y=y.to(device)\n",
        "    y_pred=model(X)\n",
        "    loss=lossfn(y_pred,y)\n",
        "    train_loss += loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss/=len(train_data_loader)\n",
        "  train_loss_values.append(train_loss)\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  test_loss=0\n",
        "  test_accuracy = 0\n",
        "  with  torch.inference_mode():\n",
        "    for X_test,y_test in test_data_loader:\n",
        "      X_test=X_test.to(device)\n",
        "      y_test=y_test.to(device)\n",
        "      y_pred_test=model(X_test)\n",
        "      test_accuracy+= accuracy_fn(y_pred_test, y_test)\n",
        "      test_loss+=lossfn(y_pred_test,y_test)\n",
        "\n",
        "\n",
        "    test_accuracy/=len(test_data_loader)\n",
        "    test_loss/= len(test_data_loader)\n",
        "    test_loss_values.append(test_loss)\n",
        "\n",
        "print(f\"test loss for each epoch = {test_loss_values}\")\n",
        "print(f\"test Accuracy={test_accuracy}\")\n",
        "print(train_loss_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KN2Lv3kgzPBd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4H8MHJ4tznD6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Dx68nZf77Mvb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "AvV8LfLg6Edl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "j6yr9T6r6kJD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "HMs2OxSZzqCe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "T8458PF60PQ6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "fsdE-WN966ik"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "EEUs0M187eeS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "298d06ac9e3b476db48667bbcd74d2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35bd6c809776438687d697c8f73cd81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92def21ee7fb44a89e4b72ac1a546935",
            "placeholder": "​",
            "style": "IPY_MODEL_298d06ac9e3b476db48667bbcd74d2f6",
            "value": " 10/10 [01:32&lt;00:00,  9.26s/it]"
          }
        },
        "35de48b0693b44f8a541c7c8366afc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_582befcd59dc49da9bcece5427f47605",
              "IPY_MODEL_9255ecee9278468fbe87f6f8a581f80e",
              "IPY_MODEL_35bd6c809776438687d697c8f73cd81d"
            ],
            "layout": "IPY_MODEL_42197ff786a845da89f919e85ae7f561"
          }
        },
        "42197ff786a845da89f919e85ae7f561": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582befcd59dc49da9bcece5427f47605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d305df4014fb46f5ac1c1e3ccf9f812e",
            "placeholder": "​",
            "style": "IPY_MODEL_be096a56515445078b7ba6abbf8d50f6",
            "value": "100%"
          }
        },
        "8528dd5decd84f3c823190ecb779ab44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9255ecee9278468fbe87f6f8a581f80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8528dd5decd84f3c823190ecb779ab44",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93940c52e845421995aa8363ec6a2e98",
            "value": 10
          }
        },
        "92def21ee7fb44a89e4b72ac1a546935": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93940c52e845421995aa8363ec6a2e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be096a56515445078b7ba6abbf8d50f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d305df4014fb46f5ac1c1e3ccf9f812e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
